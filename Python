import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import KFold #For K-fold cross validation  dige cross_validation nadarim
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, export_graphviz
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
from sklearn import metrics
import seaborn as sns
df=pd.read_csv (r"C:\Users\lenovo\Desktop\loan prediction\train1372.csv")

t1 = df.pivot_table(values=['Loan_Status'],index=['Credit_History'],aggfunc='size')
print(t1)
groupbyloan_status=df.groupby(['Credit_History','Loan_Status'])
t=groupbyloan_status.size().unstack()

t2=pd.crosstab([df.Credit_History,df.Gender],df.Loan_Status)
print(t2.unstack())  
t2.plot(kind='bar',stacked=True)
df.apply(lambda x: sum(x.isnull())  #axis=0 baraye columns in kar ro mikone
pd.isnull(df['Self_Employed']).sum()
df['Self_Employed'].isnull().sum()
t4=df['LoanAmount'].fillna(df['LoanAmount'].mean(),inplace=True)
df.boxplot(column='LoanAmount',by= ['Education','Self_Employed'] )
t5=df['Self_Employed'].value_counts()
t9=df.loc[:,['Self_Employed','Education','LoanAmount']]

t8=t9[(t9.Self_Employed=='No')& (t9.Education=='Graduate')]
df[df['LoanAmount'].isnull()]
table ['Education'=='Graduate']
t23=table ['Graduate']
print (t23)
print(table)
table['Not Graduate']
table ['No','Graduate']

t9=df.loc[:,['Self_Employed','Education','LoanAmount']]

t8=t9[(t9.Self_Employed=='No')& (t9.Education=='Graduate')]
df[df['LoanAmount'].isnull()]
table ['Education'=='Graduate']
t23=table ['Graduate']
print (t23)
print(table)
table['Not Graduate']
table ['No','Graduate']

df['Self_Employed'].fillna('No',inplace=True)  
table=df.pivot_table(values='LoanAmount', index='Self_Employed' ,columns='Education', aggfunc=np.median)
 Define function to return value of this pivot_table   
def fage(x):
     return table.loc[x['Self_Employed'],x['Education']]
     
# Replace missing values

df['LoanAmount'].fillna(df[df['LoanAmount'].isnull()].apply(fage, axis=1), inplace=True)
df['LoanAmount_log']=np.log(df['LoanAmount'])
df['LoanAmount_log'].hist(bins=20)

df['TotalIncome']=df['ApplicantIncome']+df['CoapplicantIncome']

df['TotalIncome_log']=np.log(df['TotalIncome'])
df['TotalIncome_log'].hist(bins=20)
t6=[(df['TotalIncome_log'].mean()),(df['TotalIncome_log'].mode()),(df['TotalIncome_log'].median())]
df.apply(lambda x: sum(x.isnull()))

df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)
df['Loan_Amount_Term'].fillna(df['Loan_Amount_Term'].mode()[0], inplace=True)
df['Credit_History'].fillna(df['Credit_History'].mode()[0], inplace=True)
var_mod = ['Gender','Married','Dependents','Education','Self_Employed','Property_Area','Loan_Status']
le = LabelEncoder()
for i in var_mod:
    df[i] = le.fit_transform(df[i])
    
 #Decision Tree
 
feature_cols=['Credit_History','Gender','Married','Education']
x=df[feature_cols]
y=df.Loan_Status
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=0) 
clrTree = DecisionTreeClassifier()
clrTree = clrTree.fit(x_train, y_train)
outTree = clrTree.predict(x_test)

#KNN

clrKN = KNeighborsClassifier()
clrKN = clrKN.fit(x_train, y_train)
outKN = clrKN.predict(x_test)

#Logisticregression

feature2=['Credit_History']
x1=df[feature2]
y1=df.Loan_Status
x1_train,x1_test,y1_train,y1_test=train_test_split(x1,y1,test_size=0.3,random_state=0) 
logreg=LogisticRegression()
logreg=logreg.fit(x1_train,y1_train)
outlogreg=logreg.predict(x1_test)

#Confusion matrix

cnf_matrix = metrics.confusion_matrix(y1_test, outlogreg)
print("Accuracy for Decision Tree Classifier: " + str(accuracy_score(y_test, outTree)*100)+"%")
print("Accuracy for KNeighbors Classifier: " + str(accuracy_score(y_test, outKN)*100)+"%") 
print("Accuracy for logisticregression Classifier: " + str(accuracy_score(y1_test, outlogreg)*100)+"%")
print("Confusion matrix for logistic classifier:" )
cnf_matrix

#Heatmap

class_names=[0,1] # name  of classes
fig, ax = plt.subplots()
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)

# create heatmap

sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g')
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y=1.1)
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
